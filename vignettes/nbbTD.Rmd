---
title: "Multiprocessing temporal disaggregation of time series"
output: 
  html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Multiprocessing temporal disaggregation of time series}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
author: Corentin Lemasson
abstract: The vignette explains how to perform temporal disaggregation (TD) of an annual to quarterly or monthly set of time series using the package *nbbTD*, which relies on R packages from JDemetra+. Either the sum or the average consistency between the annual benchmarks and the quarterly or monthly indicators are handled. Amongst the possible methods, the model-based proportional first difference (PFD) Denton is defined in State Space form. Transforming the standard Denton PFD method into a parametric State Space model is interesting because it allows for more flexibility. This includes the possibility to incorporate outliers (level shifts) in the Benchmark-to-Indicator (BI) ratio and/or fix the disaggragated BI ratio (and therefore also the disaggregated series) manually for some periods. The benefits related to movement preservation methods is kept while the main drawbacks of using Denton PFD as Temporal Disaggregation method - such as the high sensitivity to sudden shift in the BI ratio - can now be handled. The package *nbbTD* also tackles extrapolation. The user has the possibility to forecast the annual BI ratio which will be considered for the estimation of the 'out-of-sample' periods (approximatively when the year is still uncomplete). This is called 'enhanced Denton' and it can be done in the tool either via an automatic forecasting procedure or via manual input. In addition to the (enhanced) Denton PDF method, the traditional Chow-Lin method and its variants Fernandez and Litterman are also available. Finally, a Shiny app is provided inside the package to visualize the results and help the user to make the best decision concerning the specification of the model for each series.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The package *nbbTD* is a tool for the production of temporal disaggregated series. It handles annual to quarterly or monthly disaggregation and supports either sum or average consistency between the annual benchmarks and the infra-annual indicator. As far as methods are concerned, the model-based proportional first differences (PFD) Denton method as well as the traditional Chow-Lin method and its variants Fernandez and Litterman are currently included in the package. The Denton PFD method can be applied as such or it can be enhanced in extrapolation by forecasting the annual Benchmark-to-Indicator (BI) ratio beforehand for the year(s) with no benchmark. When the model-based Denton is used, the user also has de possibility to include outliers (shifts in the disaggregated BI ratio) and/or adjusting the disaggregated BI ratio manually. Although the package was intended for temporal disaggregation, the model-based Denton method can be used for benchmarking too.

# Theoretical aspects

## Benchmark-to-Indicator (BI) ratio

The BI ratio is the ratio between the benchmark and the indicator series. Annually, it corresponds to the ratio between the annual benchmark and the sum (or mean) of the four quarters of the indicator (assuming indicator is quarterly). On an infra-annual basis, it is the ratio between the disaggregated series and the indicator. It is interesting to monitor it closely as the annual movements of the BI ratio reflect the quality of the fit between the benchmark and the indicator. A constant BI ratio means that the growth rates of the benchmark and the indicator are similar. To the contrary, large deviations indicates different developments between the two series. A systematic analysis of the annual BI ratio can also be useful to detect anomalies in the indicator and/or the benchmark series. Often, in normal times, it can be argued that the infra-annual BI ratio should not change drastically from one period to another. When this is true, the Denton PFD method is warranted.   

## Model-Based Denton PFD method 

Traditional regression-based methods such as Chow-Lin/Fernandez have shown their limits during the Covid-19 crisis. In particular, they tend to provide disaggregated series which are excessively smoothed when the assumptions of strict exogeneity or homoscedasticity does not hold. Moreover, they can lead to large revisions of the entire series and to some issues of comparability as the smoothness of the disaggregated series depends on the fit between the benchmark and the indicator. Denton PFD method, however, preserves as much as possible the (quarter-on-quarter) movement of the indicator. Movement preservation should be the goal of any temporal disaggregation when the infra-annual indicator is the only information available and there is no relationship between the BI ratio and the indicator (or, in other words, when there is no reason to believe that the variability of the indicator is higher than that of the benchmark). However, when this is not the case, models including a constant such as Chow-Lin can be more appropriate, but the assumptions underlying the model should be scrutinized.      

Denton PFD method tends to keep the BI ratio (i.e. the ratio between the benchmark and the indicator) as constant as possible given the annual constraints. It is usually expressed in mathematical terms as a constrained minimization problem:
$$
min_{y_t}\sum^n_{t=2}\biggl[\frac{y_t}{x_t}-\frac{y_{t-1}}{x_{t-1}}\biggr]^2
$$
subject to
$$
\sum_{t} y_t = Y_y
$$
Equivalently, the Denton PFD method can also be expressed as a statistical model considering the following state space representation
$$
\begin{aligned}
y_t &= \beta_t x_t \\
\beta_{t+1} &= \beta_t + \varepsilon_t \qquad \varepsilon_t \sim {\sf NID}(0, \sigma^2_{\varepsilon})
\end{aligned}
$$
where the annual constraints are taken care of by the use of a cumulator (see Proietti (2005)). 

The state space representation of Denton PFD method makes it possible to enhance the original model by adding features. An argument against the use of Denton PFD as temporal disaggregation method is its locally high sensibility to outliers inducing problematic wave effects. From the state space representation above, one could increase some value of $\sigma^2_{\varepsilon}$ to consider a higher error of $\beta_t$, which means adding a level shift in the disaggregated BI ratio at a given point of time. The intensity of the level shift can be modified by playing with the value of $\sigma^2_{\varepsilon}$.

The disaggregated BI ratio (thus, also, indirectly the disaggregated series) can be adapted manually. For very specific quarters such as in 2020 with the Covid-19 crisis, one could use an ad-hoc method of estimation (that could be based on the analysis of the BI ratio) and introduce the results manually in the input. This offers more flexibility to the user and could be used in combination with outliers. Implementing this possibility was straightforward given the state space representation. In the example below, the missing values of the cumulated series are just filled manually before estimating the rest of the series. 
Two important points need to be mention here: 
1. when manual BI ratio are provided, they must be provided for each quarter/month of the year. 
2. the weighted average of the infra-annual BI ratio manually imported must match the annual BI ratio. When this not the case, the difference is prorated and a warning is returned to the user. 

By keeping the quarter-on-quarter growth rates of the indicator unchanged in extrapolation, the Denton PFD method makes an implicit forecast of the annual BI ratio solely based on the development of the last few annual BI ratio's. On the other hand, the so-called enhanced Denton method requires to make an explicit forecast of the annual BI ratio. In the package, the user can either use an automatic forecasting procedure or provide the forecasts manually. The automatic procedure works as such: given that the number of observations is often limited, time series models may be unstable. The choice was made to consider a random walk process (i.e. the last annual BI ratio) by default and to deviate from this assumption only when there is strong statistical evidence against it. A score is calculated as the difference in RMSE of cross-validation errors between the best alternative model and a random walk process. The score is then compared (by default) to a 95%-quantile critical value obtained by simulation. Alternative models are: average BI ratio of the last five years (three if the series is short), geometric average of the growth rates of the BI ratio in the last five years (three if the series is short) and TRAMO when the benchmark series is long enough (>= 13 years). Note that a selection of model simply based on the comparison of the score is not advisable with small sample size as it is likely that an alternative model displays a better score only by chance and not because it fits the data better. To translate the annual forecast of the BI ratio to the infra-annual extrapolated periods, we use the simplified algorithm from IMF (reference: **On the extrapolation with the Denton Proportional Benchmarking method**, p.8) when the extrapolation period does not cover the entire year yet. When the entire year is covered, an extra year is explicitly added to the benchmark series by using the forecast of the annual BI ratio. The Denton PFD method is run considering this extra year for the benchmark. A combination of the two approaches is used when the extrapolated period exceeds one year (with a maximum of two years of extrapolation).

## Chow-Lin method and its variants

Chow-Lin method and its variants is an all-in one solution largely documented in the literature and it won't be discussed in too much details here. Just to mention that the method is applied as such for both distribution and extrapolation and numerical results are returned in details in the output.

## Example

**Estimation of quarterly value added in catering industry with a turnover indicator** (mock data)

Input table

| Period      | (scaled) indicator (x) | cumulated series (yc)  | (scaled) annual  BI ratio | relative std error of $beta_t$
| ----------- | ----------- | ----------- | ----------- | ----------- |
| ...         | ...         | ...         | ...         | ...         |
| 2018-Q1     | 84.4        | NA          |             | 1           |
| 2018-Q2     | 97.9        | NA          |             | 1           |
| 2018-Q3     | 98.7        | NA          |             | 1           |
| 2018-Q4     | 99.9        | 7885        |99.8         | 1           |
| 2019-Q1     | 88.9        | NA          |             | 1           |
| 2019-Q2     | 102.8       | NA          |             | 1           |
| 2019-Q3     | 103.8       | NA          |             | 1           |
| 2019-Q4     | 104.5       | 8297        |100.0        | 1           |
| 2020-Q1     | 77.2        | 1510(e)     |             | 10          |
| 2020-Q2     | 40.8        | 2200(e)     |             | 1           |
| 2020-Q3     | 88.5        | 3922(e)     |             | 1           |
| 2020-Q4     | 50.1        | 4793        |90.1         | 1           |
| 2021-Q1     | 40.9        | NA          |             | 1           |
| 2021-Q2     | 70.4        | NA          |             | 1           |
| 2021-Q3     | 112.2       | NA          |             | 1           |
| 2021-Q4     | 102.0       | 6544        |96.9         | 1           |
| 2022-Q1     | 92.4        | NA          |             | 1           |
| 2022-Q2     | 121.2       | NA          |             | 1           |
| 2022-Q3     | 125.2       | NA          |             | 1           |
| 2022-Q4     | 123.9       | 9597(e)     |100.0(e)     | 1           |
| 2023-Q1     | 113.3       | NA          |             | 1           |

This is an example of input table. We have the quarterly indicator in the second column and the cumulated series by year in the third column. In the last quarter of each year, we have the annual benchmark and the missing values for the other quarters is what we need to estimate. In Belgium, the catering industry highly suffered of the Covid-19 crisis. Thus, for very specific quarters such as during the crisis, one could use an ad-hoc method of estimation (that could be based on a deeper analysis of the BI ratio) and introduce the results manually in the input. The fourth column shows the annual BI ratio. Prior 2020, it was quite stable translating a good fit between the benchmark and the indicator. In 2020, there was a sudden fall. A plausible explanation for this fall is the dramatic increase of the input-output ratio caused by the successive lockdowns and other measures taken by the Belgian government (the intermediate consumption falling less than turnover so that value added fell even more than turnover).  In 2021, there was still some impact of the Covid-19 on this sector. In 2022, even if we do not have the annual figure yet, we can expect the input-output ratio (and thus the BI ratio) to come back to its level from before the crisis and hence, by forecasting the annual BI ratio, we can estimate how much more the quarterly value added should increase compared to the turnover indicator. Finally, the fifth column shows relative standard error for each quarter. In Q1-2020, we add a level shift in the BI ratio by multiplying the error by a factor of 10 for example.

Output table

| Period      | cumulated series (yc) | disaggregated series (y) | (scaled) disaggregated BI ratio (y/x)
| ----------- | ----------- | ----------- | ----------- |
| ...         | ...         | ...         | ...         |
| 2018-Q1     | 1750        | 1750        | 99.9        | 
| 2018-Q2     | 3775        | 2025        | 99.8        |
| 2018-Q3     | 5817        | 2042        | 99.7        |
| 2018-Q4     | 7885        | 2068        | 99.8        |
| 2019-Q1     | 1842        | 1842        | 99.9        | 
| 2019-Q2     | 3975        | 2133        | 100.0       |
| 2019-Q3     | 6128        | 2153        | 100.0       |
| 2019-Q4     | 8297        | 2168        | 100.0       |
| 2020-Q1     | 1510        | 1510        | 94.3        | 
| 2020-Q2     | 2200        | 690         | 81.5        |
| 2020-Q3     | 3922        | 1723        | 93.9        |
| 2020-Q4     | 4793        | 871         | 83.8        |
| 2021-Q1     | 758         | 758         | 89.5        | 
| 2021-Q2     | 2138        | 1380        | 94.5        |
| 2021-Q3     | 4426        | 2288        | 98.3        |
| 2021-Q4     | 6544        | 2117        | 100.1       |
| 2022-Q1     | 1918        | 1918        | 100.0       | 
| 2022-Q2     | 4432        | 2514        | 100.0       |
| 2022-Q3     | 7028        | 2596        | 100.0       |
| 2022-Q4     | 9597        | 2570        | 100.0       |
| 2023-Q1     | 2349        | 2349        | 100.0       |

Once estimated, we can easily derive the disaggregated series and the disaggregated BI ratio from the cumulated series.

# R tool

## Quick start

Install and load package
```{r, eval=FALSE}
install.packages("nbbTD")
library("nbbTD")
```

Once the package is loaded, there are three steps to follow:
1. Prepare input either directly in R or in an structured Excel (.xlsx) file. The structure of the input in R is explained in details in the documentation of the main function (see ?multiTD) and in the section related to the description of the functions below. For the Excel file, a template is provided as part of the package (together with the vignette). The content of each sheet is also described in the section related to the description of the functions below. Be aware that indicators name must start with the name of the related benchmark series but the name may be extended using an underscore.  
2. Run main function and stock the results into a variable
3. Check results and display them using the Shiny App 

```{r, eval=FALSE}
# Step 1: input data
Y<-cbind(rjd3toolkit::aggregate(rjd3toolkit::retail$RetailSalesTotal, 1),
         rjd3toolkit::aggregate(rjd3toolkit::retail$ClothingStores, 1))
colnames(Y)<-c("retail","clothing")
x<-cbind(rjd3toolkit::retail$FoodAndBeverageStore,
         rjd3toolkit::retail$AutomobileDealers,
         rjd3toolkit::retail$WomensClothingStores)
colnames(x)<-c("retail_food", "retail_cars", "clothing_womens")
outliers<-list(clothing=c("20081001"=10))

# Step 2: run main function
rslt<-multiTD(Y, x, model=list(retail="Chow-Lin", clothing="mbDenton"), outliers=outliers)

# Step 3: analyse results
print(rslt)
#rslt$...

runShiny(rslt)
```

## Description of the functions

To list the functions available in the package; 
```{r, eval=FALSE}
ls("package:nbbTD")
```

Use help('name of the functions') or ?'name of the functions' for more information and examples over the function. 

### multiTD()

The function **multiTD()** performs multiprocessing (or single processing if there is only one series) temporal disaggregation of time series of an annual to quarterly or monthly set of time series. Either the sum or the average consistency between the annual benchmarks and the quarterly or monthly indicators are handled.

During the execution of the code, a (non-exhaustive) number of tests are performed and warnings are returned to assist the user in the analysis of the results and for the specification of the models. It is strongly recommended to read carefully each warning message. 


```{r, eval = FALSE}
# Call
multiTD(
    benchmarks,
    indicators,
    model = "mbDenton",
    outliers = NULL,
    disagBIfixed = NULL,
    forecastBI = c("none", "auto", "userdefined+none", "userdefined+auto"),
    forecastBI.values = NULL,
    forecastBI.quantile = c("q.95", "q.80", "q.90", "q.99", "q.999"),
    freezeT1 = FALSE,
    conversion = c("Sum", "Average"),
    path_xlsx = ""
)
```

**benchmarks** and **indicators**: The datasets containing the benchmarks and the indicators series must respect some rules described in the documentation of the function (see ?multiTD). In particular, indicators name must start with the name of the related benchmark series but the name may be extended using an underscore. This is for the sake of security to avoid associating the wrong indicator to a benchmark series. Benchmark and indicator series can be imported into RStudio from anywhere. If the data are located in an Excel file, they could be imported using for example the function **read_excel** from the package 'readxl'. 

**model**: allows the user to choose currently between five models: 'mbDenton', 'Chow-Lin', 'Fernandez' and 'Litterman', 'Chow-Lin_no_cst'. If the selected model is the same for all the series, it can be specified as a string. If the model is different between the series, the user must provide a structured list. The name of the series must be submitted first and must be followed by an equal sign and the model's name (e.g. list(retail="Chow-Lin", clothing="mbDenton")). 'mbDenton' is the method by default. Note that the difference between 'Chow-Lin' and 'Chow-Lin_no_cst' lies in the inclusion or not of a constant term in the regression. 

For the series where 'mbDenton' model is selected, the user can use the following arguments:

* **outliers**: to add outliers, i.e., level shift in the disaggragated BI ratio. They must be specified as a list of structured definition of the outlier periods and their intensity for each series. The name of the series must be submitted first. This must be followed by an equal sign and the outliers description inside a vector (i.e., c(o1,o2,etc.)). The outliers description must start with the period formatted as YYYYMMDD and enclosed in quotation marks, then an equal sign and the intensity of the outlier, defined as the relative value of the 'innovation variances' (1= normal situation). Note that the scale between 1(normal value) to 5 or 10 for example is not linear but exponential.
e.g. list(retail=c("20081001"=10, "20090101"=10),clothing=c("20081001"=10))

* **disagBIfixed**: to fix some disaggragated BI ratios: They must be specified as a list of structured definition of the periods of the disaggragated BI ratios and their values for each series. The name of the series must be submitted first. This must be followed by an equal sign and the disaggragated BI ratios inside a vector (i.e., c(bi1,bi2,etc.)). The disaggragated BI ratio must start with the period formatted as YYYYMMDD and enclosed in quotation marks, then an equal sign and the value of the BI ratio at that period. When fixed disaggregated BI ratio are provided, they must be provided for each quarter/month of the year. Furthermore, the weighted average of the manual infra-annual BI ratio must match the value of the annual BI ratio. The difference is prorated and when the discrepancy is too important, and a warning is thrown. 
e.g. disagBIfixed = list(retail=c("20080101"=7.246695, "20080401"=7.246695, "20080701"=7.246695, "20081001"=6.0))

* To consider forecast of the annual BI ratio: 

  - **forecastBI**: there are four options: "none", "auto", "userdefined+none", "userdefined+auto". The first one means "no forecast" and correspond to the standard Denton method. The second one means that the user wants to use the automatic forecast (as explained above) for each series.  The third one means that the user wants to use manual forecasts for some (or all) the series specified in the argument forecastBI.values and no forecast for the other series. The last one means that the user wants to use manual forecasts for some (or all) the series specified in the argument forecastBI.values and automatic forecast for the other series. Note that as part of the output, an alternative forecasts is given, which come from the best alternative models - or the second best if an automatic forecast is specified instead of a userdefined forecast - in terms of cross validation errors. This alternative forecast is returned only for the sake of comparison.

  - **forecastBI.values**: the user can can bring in the manual forecast of the annual BI ratio. Manual forecast must be specified as a list of structured definition of the forecast values for each series. The name of the series must be submitted first. This must be followed by an equal sign and the forecasted values inside a vector of two values (i.e., c(f_y+1,f_y+2)). The forecasted values must start with "Y+1" and "Y+2" respecively (enclosed in quotation marks), followed by an equal sign and the value of the forecast.
e.g. forecastBI.values = list(retail=c("Y+1"=6.8, "Y+2"=7.0))

  - **forecastBI.quantile**: allows the user to set how much evidence is required to switch from a random walk process to the best of TRAMO / mean of the last 5 years / geometric mean of growth rates of the last 5 (or 3) years in the automatic selection of the forecasting model for the annual benchmark. For instance, when the quantile 'q.80' is specified instead of the default 'q.95', less evidence is required to switch to the alternative model. Note that the package includes a data set called **table_rw** which contains the critical values to consider for the selection of the forecasting model of the annual BI ratio when enhanced Denton is used as temporal disaggregation model.

  - **freezeT1**: specific argument. It is only relevant when 'mbDenton' model is used and when the extrapolation period matches one year exactly. In this case, when freezeT1=TRUE, the approximation from IMF continues to be applied, meaning no revision in the past of the series. When freezeT1=FALSE (or anyway when the period of extrapolation exceeds one year), an extra year is implicitly added to the benchmark (by using the forecast of the annual BI ratio if any) before running the model, implying revision of the past of the series.

Currently, anything related to outliers, fixed disaggregated BI ratio or forecast of annual BI ratio are only handled with model-based Denton. When a specification cannot be handled given the selected model (e.g. if we define an outlier for a series treated with Chow-Lin), it is ignored and a warning is thrown. Similarly, you'll also have a warning message if you have more than one indicator with a model-based Denton. 

**conversion**: the type of consistency to consider between the annual benchmarks and the infra-annual indicators. 'Sum'/'Average' means that the annual sum/average of the infra-annual disaggregated series must match the benchmark.

**path.xlsx**: export the main results directly into an Excel file.

### multiTD_fromXLSX()

The function **multiTD_fromXLSX()** is the same as **multiTD()**, but when the input come from an Excel file (.xlsx).

```{r, eval = FALSE}
# Call
multiTD_fromXLSX(path_data,
                 forecastBI = c("none", "auto", "userdefined+none", "userdefined+auto"),
                 forecastBI.quantile = c("q.95", "q.80", "q.90", "q.99", "q.999"),
                 freezeT1 = FALSE,
                 conversion = c("Sum", "Average"),
                 path_output = NULL
                 )
```


**path_data**: path of the .xlsx file containing the input. The file must be composed of six sheets called 'benchmarks', 'indicators', 'models', 'outliers', 'disag_BI_fixed' and 'forecast_annual_BI'. Here is a template for each sheet:

- benchmarks

| DATE        | seriesname1   | seriesname2   | ...         |
| ----------- | -----------   | -----------   | ----------- |
| 01/01/1992  | 1815716       | 85459         | ...         |
| 01/01/1992  | 1942248       | 88222         | ...         |
| ...         | ...           | ...           | ...         |

- indicators

| DATE        | seriesname1_x  | seriesname2_x1 | seriesname2_x2 | ...         | 
| ----------- | -----------    | -----------    | -----------    | ----------- |
| 01/03/1992  | 88058          | 83191          | 6272           | ...         |
| 01/06/1992  | 92907          | 94661          | 7847           | ...         |
| ...         | ...            | ...            | ...            | ...         |

- models

| seriesname  | model         | 
| ----------- | -----------   | 
| seriesname1 | Chow-Lin      | 
| seriesname2 | mbDenton      | 
| ...         | ...           | 

- outliers

| seriesname  | period        | intensity     | 
| ----------- | -----------   | -----------   | 
| seriesname2 | 20081001      | 10            | 
| ...         | ...           | ...           | 

Format of the period column must be: YYYYMMDD all attached (note that DD can be anything and, for quarterly data, MM can be any month inside the quarter. The intensity is defined as the relative value of the 'innovation variances' (1=normal situation). Note that the scale between 1(normal value) to 5 or 10 for example is not linear but exponential.

- disag_BI_fixed

| seriesname  | period        | intensity     | 
| ----------- | -----------   | -----------   | 
| seriesname2 | 20080101      | 4.10          | 
| seriesname2 | 20080401      | 4.12          | 
| seriesname2 | 20080701      | 4.13          | 
| seriesname2 | 20081001      | 4.11          | 
| ...         | ...           | ...           | 

Format of the period column must be: YYYYMMDD all attached (note that DD can be anything and, for quarterly data, MM can be any month inside the quarter. When fixed disaggregated BI ratio are provided, they must be provided for each quarter/month of the year. Furthermore, the weighted average of the manual infra-annual BI ratio must match the value of the annual BI ratio. The difference is prorated and when the discrepancy is too important, and a warning is thrown.

- forecast_annual_BI

| seriesname  | f_T1          | f_T2          | 
| ----------- | -----------   | -----------   | 
| seriesname2 | 4.3           | 4.35          | 
| ...         | ...           | ...           |  

**forecastBI**: only relevant with model-base Denton. Four options: "none", "auto", "userdefined+none", "userdefined+auto". The first one means "no forecast" and correspond to the standard Denton method. The second one means that the user wants to use the automatic forecast (as explained above) for each series. The third one means that the user wants to use manual forecasts for some (or all) the series specified in the sheet 'forecast_annual_BI' and no forecast for the other series. The last one means that the user wants to use manual forecasts for some (or all) the series specified in the sheet 'forecast_annual_BI' and automatic forecast for the other series. Note that as part of the output, an alternative forecasts is given, which come from the best alternative models - or the second best if an automatic forecast is specified instead of a userdefined forecast - in terms of cross validation errors. This alternative forecast is returned only for the sake of comparison.

**forecastBI.quantile**: only relevant with model-base Denton. Allows the user to set how much evidence is required to switch from a random walk process to the best of TRAMO / mean of the last 5 years / geometric mean of growth rates of the last 5 (or 3) years in the automatic selection of the forecasting model for the annual benchmark. For instance, when the quantile 'q.80' is specified instead of the default 'q.95', less evidence is required to switch to the alternative model.

**freezeT1**: specific argument. It is only relevant with model-base Denton and when the extrapolation period matches one year exactly. In this case, when freezeT1=TRUE, the approximation from IMF continues to be applied, meaning no revision in the past of the series. When freezeT1=FALSE (or anyway when the period of extrapolation exceeds one year), an extra year is implicitly added to the benchmark (by using the forecast of the annual BI ratio if any) before running the model, implying revision of the past of the series.

**conversion**: the type of consistency to consider between the annual benchmarks and the infra-annual indicators. 'Sum'/'Average' means that the annual sum/average of the infra-annual disaggregated series must match the benchmark.

**path.output**: path to export the main results directly into an Excel file.


### mbdenton()

The function **mbdenton()** performs a single processing temporal disaggregation of time series of an annual to quarterly or monthly set of time series using the model-base Denton method. Either the sum or the average consistency between the annual benchmarks and the quarterly or monthly indicators are handled.

```{r, eval = FALSE}
# Call
mbdenton (indicator,
          benchmark,
          outliers = NULL,
          outliers.intensity = 10,
          manual_disagBI = NULL,
          conversion = c("Sum", "Average"))
```

**indicator**: monthly or quarterly indicator. Must be a ts object.

**benchmark**: annual benchmark. Must be a ts object.

**outliers**: To add outliers, i.e., level shift in the disaggragated BI ratio. Must be specified as a numeric vector with the outlier periods in decimal dates.
e.g. outliers<-c(2008.75,2009.00) # add outliers in Q4-2008 and Q1-2009

**outliers.intensity**: intensity of the  outlier, defined as the relative value of the 'innovation variances' (1= normal situation). Must be specified as a numeric vector corresponding to the outlier periods specified in the outliers argument. Default value is 10. Note that the scale between 1(normal value) to 10 is not linear but exponential.
e.g. outliers.intensity<-c(10,5)

**manual.disagBI**: Disaggregated BI ratio that the user wants to fix. Must be as a matrix of two columns called 'period' and 'bi_ratio'. The periods must be in decimal. When fixed disaggregated BI ratio are provided, they must be provided for each quarter/month of the year. The weighted average of the manual infra-annual BI ratio must match the value of the annual BI ratio. The difference is prorated and when the discrepancy is too important, and a warning is thrown.
e.g. manual_disagBI<-matrix(cbind(c(2008.00,2008.25,2008.50,2008.75),                       c(7.246695,7.246695,7.246695,6.0)) 

**conversion**: the type of consistency to consider between the annual benchmarks and the infra-annual indicators. 'Sum'/'Average' means that the annual sum/average of the infra-annual disaggregated series must match the benchmark.


# Output

## Content

The output of the function **multiTD()** is an object of class 'nbb.multiTD.output' which contain many information intended to help the user evaluate the quality of the results and take informed decision concerning the specifications of the models (see also section '*nbbTD* in production') for each series. Numeric results will be discussed in this section. Graphical analysis is of primary interest in temporal disaggregation. The function **runShiny()** displays informative charts to help the user to intepret the results. See section 'Shiny App' for more details.

Here are the First-level output. First-level means that they are accessible using a single'$' sign after the variable name containing the results (e.g. rslt$td_series).   

* *series_names*: detailed output for each disaggregated series. This includes the estimates of the parameters. When Chow-Lin or Litterman is used, it is important to verify the value of $\rho$.A negative value of $\rho$ leads to spurious results and should be avoided. The closer the value is from 1, the more 'memory' and the slower it converges to the long-term mean in extrapolation. On the other hand, a value of rho close to 0 means that we are close to a simple OLS model where the errors are simply divided by 4 (quarterly indicator) with a potential step effect resulting from this. A warning is thrown when the value of rho reaches undesirable values.      
* *call*: the function call
* *benchmarks*: the benchmarks series
* *indicators*: the indicators series
* *td_models*: the temporal disaggregated model used for each series
* *td_series*: the disaggregated series
* *td_series_stderr*: the standard error of the disaggregated series
* *td_bi*: the disaggragated BI ratio ($td.bi=\frac{ts.series}{indicator}$)
* *td_bi_stderr*: the standard error of the disaggragated BI ratio
* *bi_annual*: the annual BI ratio
* *bi_annual_f*: forecasts of the annual BI ratio for years T+1 and T+2. While this is defined explicitly with 'enhanced' Denton, this is not the case with the other methods. If the extrapolation period exceeds (or equals) one year, the implicit forecast of the annual BI ratio is provided in those cases. Otherwise NA are returned.
* *bi_annual_falt*: alternative forecast of the annual BI ratio for years T+1 and T+2. Only returned for the sake of comparison. When the selected forecasting model is random walk, the alternative forecast comes from the best alternative model that are tested (i.e., mean of last 5 (3) years, geometric mean of growth rates of last 5 (3) years or TRAMO). When the selected forecasting model is not random walk or is defined by the user, the alternative forecasts come from random walk. *bi.annual.falt* is define as 'NA' when no enhanced Denton is used.
* *decomposition*: separates the regression effect from the smoothing effect in the disaggregated series. Only interesting with Chow-Lin and its variants as smoothing effect are null with model-based Denton.
* *fit*: it is not recommended to use an indicator which fits the benchmark poorly. For an overall measure of the fit, an Ols regression between the growth rates of the annual benchmark and the growth rates of the annualized indicator is performed for each series. The t-stat and the p-value of the parameter are returned. The higher(lower) the t-stat(p-value), the higher the fit between the benchmark and the indicator. Note that if the |t-stat| < 2, there is no statistical evidence of relationship between the benchmark and the indicator overall. A negative t-stat means that there is an inverse relationship between the benchmark and the indicator. In this case, it should be checked it makes sense. In addition, a second Ols regression is performed between the growth rates of the annual BI ratio and the growth rates of the annualized indicator. If the parameter is significant, especially when its estimate is negative, it might indicate that the indicator tends to overestimate the benchmark in absolute terms. In such cases, it rather warrants a model that includes a constant term such as Chow-Lin. Please keep in mind that Ols regression are very sensitive to outliers and, more generally, the results can be misleading when we strongly deviate from the assumptions behind the model.
* *conversion*: the defined conversion

## print(), summary(), plot()

Those returns some of the main output. 

## Shiny App

In addition to numeric output, the package includes a Shiny App to help visualize the results. The UI is accessible directly by calling the function **runShiny()**. This function requires a single argument of class 'nbb.multiTD.output' (the output of the main functions **multiTD()** or **multiTD_fromXLSX()**).

```{r, eval = FALSE}
runShiny(rslt)
```

The Shiny app is divided in three parts. 

The first part on the top left side of the window is composed of a single drop down list where the user select the series to analyse.

The second part on the top right side of the window includes informative charts **on an annual basis**. There are five clickable tabs:

* *Growth chart*: by comparing the annual development of the benchmark and the indicator, it gives an insight of the global fit but also of the local fit on the last few years for instance. It also helps to identify problematic years displaying a larger mismatch.

* *Scaled annual BI ratio*: it shows the development of the scaled annual BI ratio. The forecasts are also displayed for the years T+1 and T+2 if any. When another model is used, the implicit forecast of the year T+1 is displayed as long as the extrapolation period is long enough. Graphical analysis of the annual BI ratio is a good way to evaluate the fit between the benchmark and the indicator through time. A stable BI ratio between two consecutive periods means that the benchmark and the indicator evolve in parallel. Conversely, an upward/downward shift in the BI ratio translates a positive/negative difference in the development between the annual benchmark and the annualized indicator. Scaling the BI ratio around an average value of 100 allows the user to interpret approximately the difference in terms of percentage.

* *Annual BI ratio*: same as *Scaled annual BI ratio* but the BI ratio is not scaled. Compared to the previous tab, the level of the BI ratio can be seen. This can be useful if the user wants to adapt the forecast manually based on the graph.

* *Annual BI ratio AF*: "AF" means "Alternative Forecast if any. When the primary forecasts come from a random walk process, the AF shows the forecasts from the best alternative model (from those selected in the automatic procedure). No forecast are displayed here when another method than 'enhanced' Denton is used.   

* *Fit*: Display the results of two Ols regressions. It is not recommended to use an indicator which fits the benchmark poorly. For an overall measure of the fit, an Ols regression between the growth rates of the annual benchmark and the growth rates of the annualized indicator is performed for each series. The t-stat and the p-value of the parameter are returned. The higher(lower) the t-stat(p-value), the higher the fit between the benchmark and the indicator. Note that if the |t-stat| < 2, there is no statistical evidence of relationship between the benchmark and the indicator overall. A negative t-stat means that there is an inverse relationship between the benchmark and the indicator. In this case, it should be checked it makes sense. In addition, a second Ols regression is performed between the growth rates of the annual BI ratio and the growth rates of the annualized indicator. If the parameter is significant, especially when its estimate is negative, it might indicate that the indicator tends to overestimate the benchmark in absolute terms. In such cases, it rather warrants a model that includes a constant term such as Chow-Lin. Please keep in mind that Ols regression are very sensitive to outliers and, more generally, the results can be misleading when we strongly deviate from the assumptions behind the model.

The third part on the bottom right of the window includes informative charts **on an quarterly basis**. There are three clickable tabs:

* *TD series*: the disaggregated series with confidence interval

* *TD BI ratio*: the disaggrageted BI ratio ($td.bi=\frac{ts.series}{indicator}$) with confidence interval.

* *Decomposition*: It decomposes the disaggregated series between the regression part and the smoothing part. For Chow-Lin model and its variant, it gives an insight of the part of the disaggregated series coming from the indicator and the part being smoothed. This tab is not informative for model-based Denton where the whole disaggregated series is associated to the regression part.


# *nbbTD* in production

The processing time of **multiTD()** is very short.

When the time comes to review the models (or some elements of it), the suggestion is to proceed by trial and error by running the function as many time as necessary. For example, whether to include an outlier or not and set its intensity is something to test. The warnings are also here to help even though they are not exhaustive and both the numeric and graphical output should always be thoroughly analyzed for each series.

A typical step-by-step approach could be:

1. Run **multiTD()** a first time using default, previous or any specifications you think the best for each series
2. Check the annual fit between the benchmark and the indicator numerically and graphically. Is the indicator relevant? Are there years where the BI ratio changes suddenly? Why? Although there can be economical or structural reasons for that, inspection of the annual BI ratio can also be a good way to rapidly detect errors in either the indicator or the benchmark. If the reason is economical or structural and you want to use Denton model, should the shock be smoothed (potentially causing wave effect) or is it preferable to add a shift in the BI ratio by defining outlier/manual change (or both)? When Denton model is used, is the automatic forecast of the annual BI ratio good enough for extrapolation? You can adapt it manually if you have other information or (with caution), possibly after checking the alternative forecasts. If Chow-Lin method or one of its variant is used in presence of a large shock such as the Covid-19 crisis, wouldn't it be relevant to add a second (instrumental) indicator to capture the non-linearity specific to this period?   
3. Read the warning messages and check the disaggragated results (both numeric and graphic). Is there irrelevant input? Is there evidence to adapt the model for some series? While Denton PFD method preserves the quarter-on-quarter movement of the indicator as much as possible, Chow-Lin method and its variants tend to smooth the discrepancies between the benchmark and the indicator. Both types of method rely on a number of assumptions which should be scrutinized. Chow-Lin method and its variants assumes homoscedasticity but also strict exogeneity which can be a poor assumption in the context of National Accounts for example where many changes in methodology, sources, population and even relationship between benchmark and indicator occur through time. With Denton, the relationship between benchmark and indicator is not fixed but is assumed to evolve smoothly over time. Large discrepancies can significantly affect Denton results locally inducing potential wave effects. This makes Denton PFD method even more sensitive to outliers (locally) than Chow-Lin and variants where outliers rather have a global impact on the coefficients. Finally, it should be noted that with Denton, the impact of revision in the latest benchmark/indicator values of the series decrease quickly as we go backwards in time. This is not the case with Chow-Lin and its variants.
4. Change input if necessary and re-run the function multiTD()
5. Repeat steps 2 and 3 until the results for all series are satisfying


# References

* *IMF (2017) ‘Quarterly National Accounts Manual’, 2017 edition (p.86-126)*
* *Eurostat (2018) ‘ESS guidelines on temporal disaggregation, benchmarking and reconciliation’, 2018 edition.*
* *Chamberlin G. (2010) ‘Temporal disaggregation’, Office for National Statistics, Economic & Labour Market Review, November.*
* *Chow, G., & Lin, A.L. (1971) ‘Best linear unbiased distribution and extrapolation of economic time series by related series’, Review of Economic and Statistics, 53, 372-375.*
* *Proietti (2005) 'Temporal Disaggregation by State Space Methods: Dynamic Regression Methods Revisited'*
* *Quilis E. (2018) ‘Temporal disaggregation of economic time series: The view from the trenches’, Wiley, June.*
